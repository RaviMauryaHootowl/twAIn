{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TExt2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqaCKDO_zp5W",
        "colab_type": "code",
        "outputId": "d5e48436-cb4f-4c20-af27-86d102bfe2df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 47kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 25.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (3.2.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.9.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 42.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.8.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.18.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.34.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.28.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (46.1.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.2.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.7.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0) (2.10.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=c10db212381390f67adffb9d324f920b920ce9855439a694911a3209cfe36a8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 2.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement tensorflow-estimator<2.3.0,>=2.2.0rc0, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, gast, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed gast-0.2.2 tensorboard-2.0.2 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdFXDh0Jz9Ai",
        "colab_type": "code",
        "outputId": "ec294677-d05b-4086-b943-73b34024f9cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "!pip install keras==2.3.1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.18.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfwXxYh2jtXW",
        "colab_type": "code",
        "outputId": "5b479d4a-eae7-4ba8-d9d7-b52aa4d77d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D7D2t75mMe-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fou3BJ0Em32B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_file1 = open(\"alchemist.txt\", \"r\", encoding='utf8')\n",
        "data_file2 = open(\"metamorphosis.txt\", \"r\", encoding='utf8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iem2JVCNosZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1 = data_file1.read()\n",
        "data2 = data_file2.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQp8hRqZo37d",
        "colab_type": "code",
        "outputId": "5af36bff-f4c9-4951-931b-d1acb8c2cc0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(\"Length of Book 1 : \", len(data1))\n",
        "print(\"Length of Book 2 : \", len(data2))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Book 1 :  212244\n",
            "Length of Book 2 :  119164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITzup7_eo4_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filterAlpha(text):\n",
        "    text = text.replace('\\n', ' ')\n",
        "    s_result = []\n",
        "    for i in text:\n",
        "        if i.isalpha() or i == ' ':\n",
        "            s_result.append(i.lower())\n",
        "    return ''.join(s_result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo2OE1a5o8SN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ac274b7b-7f40-41ce-d362-9f3b32c760bd"
      },
      "source": [
        "def removeSpecialChars(data):\n",
        "  data = filterAlpha(data)\n",
        "  data = re.sub(' +', ' ', data)\n",
        "  data = data.strip()\n",
        "  return data\n",
        "\n",
        "data1 = removeSpecialChars(data1)\n",
        "data2 = removeSpecialChars(data2)\n",
        "\n",
        "#After removing punctuations\n",
        "print(\"Length of Book 1 : \", len(data1))\n",
        "print(\"Length of Book 2 : \", len(data2))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Book 1 :  200354\n",
            "Length of Book 2 :  115348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnysphABo9ni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJWhuiPeo-tq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens1 = data1.split()\n",
        "tokens2 = data2.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0OLq6cAo_2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy6XCtZUpBZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trtUIaFqpTOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = set(tokens1 + tokens2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZw6KhRpikjA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "47bbf039-6c79-4186-b875-0b0f91c9b7d0"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4637"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkOFHklPpUgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "length = 50 + 1\n",
        "lines = []\n",
        "for i in range(length, len(tokens1)):\n",
        "    seq = tokens[i-length : i]\n",
        "    line = ' '.join(seq)\n",
        "    lines.append(line)\n",
        "for i in range(length, len(tokens2)):\n",
        "    seq = tokens[i-length : i]\n",
        "    line = ' '.join(seq)\n",
        "    lines.append(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD0IiS4ZpYOz",
        "colab_type": "code",
        "outputId": "67821294-bdaf-433b-f283-8147e1cff1e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(lines)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60750"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5ELcA3CpZuN",
        "colab_type": "code",
        "outputId": "8608693a-5a52-47bd-a268-9ca56cad0bbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "lines[0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the boys name wassantiago dusk was falling as the boy arrived with his herd at an abandoned church the roof had fallen in long ago and an enormous sycamore had grown on the spot where the sacristy had once stood he decided to spend the night there he saw to it'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgqZzwu2pbgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKg0Z1JSpcxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZqnfY0hpeCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.fit_on_texts(lines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it-Fu7e1pfS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(lines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDW6CHmKpgSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = np.array(sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "518eMA9aphjY",
        "colab_type": "code",
        "outputId": "51928263-4a08-48fe-8b2a-e7b246b966dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "print(len(sequences))\n",
        "print(sequences)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60750\n",
            "[[   1  214  369 ...  151    2   13]\n",
            " [ 214  369 3316 ...    2   13    7]\n",
            " [ 369 3316 1696 ...   13    7   39]\n",
            " ...\n",
            " [ 535  182  648 ...    1 2675    5]\n",
            " [ 182  648    3 ... 2675    5 1056]\n",
            " [ 648    3   16 ...    5 1056    4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp24MYAQpjBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sequences[0, :-1]\n",
        "X, y = sequences[:, :-1], sequences[:, -1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrcyX2BYpkub",
        "colab_type": "code",
        "outputId": "bd0120f6-59d8-4ca2-8d52-aea49d562650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "X[0]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,  214,  369, 3316, 1696,    8, 2673,   21,    1,   12,  653,\n",
              "         20,   11, 3314,   22,   62, 1492,  706,    1, 1188,    9,  652,\n",
              "         10,  255,  431,    4,   62,  841,  840,    9, 1496,   32,    1,\n",
              "       1694,   87,    1, 1494,    9,  191,  520,    3,  190,    2,  476,\n",
              "          1,  155,   29,    3,  151,    2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MXtET0Rpl69",
        "colab_type": "code",
        "outputId": "a25476c5-0e3e-4dc9-ccdb-ce6035b708ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP-CCl5QpnWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = to_categorical(y, num_classes = vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZix_ySnpok5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_length = X.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjab92oOpprd",
        "colab_type": "code",
        "outputId": "a7fe7f71-bc1c-4ed2-91e4-742035ade408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "seq_length"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxwO-KF7pq-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WX6ZUukpsSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NEtBmXupt4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(LSTM(125, return_sequences=True, dropout=0.2))\n",
        "model.add(LSTM(125, dropout=0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08l89hGvpu9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(100, activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvR6Snd4p0mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(vocab_size, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qh63fMPp1xP",
        "colab_type": "code",
        "outputId": "3a6f6836-c59c-44ca-ffe0-0947075ff784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 50, 50)            165900    \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 50, 125)           88000     \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 125)               125500    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               12600     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3318)              335118    \n",
            "=================================================================\n",
            "Total params: 727,118\n",
            "Trainable params: 727,118\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7so_msofp35n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss ='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ8KTvD0p527",
        "colab_type": "code",
        "outputId": "47c59da6-0fa3-43d4-8664-cb842408db4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X, y, batch_size=128, epochs=100)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60750 samples\n",
            "Epoch 1/100\n",
            "60750/60750 [==============================] - 25s 415us/sample - loss: 6.0739 - accuracy: 0.0902\n",
            "Epoch 2/100\n",
            "60750/60750 [==============================] - 21s 350us/sample - loss: 5.5717 - accuracy: 0.1088\n",
            "Epoch 3/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 5.3451 - accuracy: 0.1279\n",
            "Epoch 4/100\n",
            "60750/60750 [==============================] - 21s 351us/sample - loss: 5.1847 - accuracy: 0.1363\n",
            "Epoch 5/100\n",
            "60750/60750 [==============================] - 21s 347us/sample - loss: 5.0680 - accuracy: 0.1437\n",
            "Epoch 6/100\n",
            "60750/60750 [==============================] - 21s 347us/sample - loss: 4.9420 - accuracy: 0.1491\n",
            "Epoch 7/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 4.8233 - accuracy: 0.1570\n",
            "Epoch 8/100\n",
            "60750/60750 [==============================] - 21s 347us/sample - loss: 4.7442 - accuracy: 0.1615\n",
            "Epoch 9/100\n",
            "60750/60750 [==============================] - 21s 347us/sample - loss: 4.6849 - accuracy: 0.1655\n",
            "Epoch 10/100\n",
            "60750/60750 [==============================] - 21s 346us/sample - loss: 4.5911 - accuracy: 0.1706\n",
            "Epoch 11/100\n",
            "60750/60750 [==============================] - 21s 347us/sample - loss: 4.5058 - accuracy: 0.1734\n",
            "Epoch 12/100\n",
            "60750/60750 [==============================] - 21s 347us/sample - loss: 4.4200 - accuracy: 0.1760\n",
            "Epoch 13/100\n",
            "60750/60750 [==============================] - 21s 346us/sample - loss: 4.3600 - accuracy: 0.1797\n",
            "Epoch 14/100\n",
            "60750/60750 [==============================] - 21s 346us/sample - loss: 4.2853 - accuracy: 0.1839\n",
            "Epoch 15/100\n",
            "60750/60750 [==============================] - 21s 347us/sample - loss: 4.2104 - accuracy: 0.1873\n",
            "Epoch 16/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 4.1355 - accuracy: 0.1899\n",
            "Epoch 17/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 4.0583 - accuracy: 0.1933\n",
            "Epoch 18/100\n",
            "60750/60750 [==============================] - 21s 353us/sample - loss: 3.9860 - accuracy: 0.1967\n",
            "Epoch 19/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 3.9142 - accuracy: 0.2007\n",
            "Epoch 20/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 3.8499 - accuracy: 0.2058\n",
            "Epoch 21/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 3.7803 - accuracy: 0.2088\n",
            "Epoch 22/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 3.7167 - accuracy: 0.2140\n",
            "Epoch 23/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 3.6516 - accuracy: 0.2187\n",
            "Epoch 24/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 3.5932 - accuracy: 0.2267\n",
            "Epoch 25/100\n",
            "60750/60750 [==============================] - 21s 347us/sample - loss: 3.5316 - accuracy: 0.2323\n",
            "Epoch 26/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 3.4734 - accuracy: 0.2386\n",
            "Epoch 27/100\n",
            "60750/60750 [==============================] - 21s 347us/sample - loss: 3.4172 - accuracy: 0.2449\n",
            "Epoch 28/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 3.3663 - accuracy: 0.2511\n",
            "Epoch 29/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 3.3127 - accuracy: 0.2570\n",
            "Epoch 30/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 3.2649 - accuracy: 0.2658\n",
            "Epoch 31/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 3.2178 - accuracy: 0.2707\n",
            "Epoch 32/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 3.1676 - accuracy: 0.2778\n",
            "Epoch 33/100\n",
            "60750/60750 [==============================] - 22s 355us/sample - loss: 3.3289 - accuracy: 0.2687\n",
            "Epoch 34/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 3.5359 - accuracy: 0.2512\n",
            "Epoch 35/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 3.2954 - accuracy: 0.2709\n",
            "Epoch 36/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 3.3165 - accuracy: 0.2713\n",
            "Epoch 37/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 3.2838 - accuracy: 0.2741\n",
            "Epoch 38/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 3.2023 - accuracy: 0.2829\n",
            "Epoch 39/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 3.1174 - accuracy: 0.2923\n",
            "Epoch 40/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 3.0489 - accuracy: 0.3018\n",
            "Epoch 41/100\n",
            "60750/60750 [==============================] - 21s 347us/sample - loss: 3.0874 - accuracy: 0.3006\n",
            "Epoch 42/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 3.0263 - accuracy: 0.3073\n",
            "Epoch 43/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 2.9394 - accuracy: 0.3193\n",
            "Epoch 44/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 2.8864 - accuracy: 0.3290\n",
            "Epoch 45/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 2.8290 - accuracy: 0.3381\n",
            "Epoch 46/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 2.8330 - accuracy: 0.3359\n",
            "Epoch 47/100\n",
            "60750/60750 [==============================] - 21s 351us/sample - loss: 2.7908 - accuracy: 0.3441\n",
            "Epoch 48/100\n",
            "60750/60750 [==============================] - 21s 352us/sample - loss: 2.7481 - accuracy: 0.3495\n",
            "Epoch 49/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 2.7162 - accuracy: 0.3563\n",
            "Epoch 50/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 2.6758 - accuracy: 0.3641\n",
            "Epoch 51/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 2.6419 - accuracy: 0.3701\n",
            "Epoch 52/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 2.6077 - accuracy: 0.3736\n",
            "Epoch 53/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 2.6094 - accuracy: 0.3769\n",
            "Epoch 54/100\n",
            "60750/60750 [==============================] - 21s 347us/sample - loss: 2.6211 - accuracy: 0.3750\n",
            "Epoch 55/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 2.5655 - accuracy: 0.3840\n",
            "Epoch 56/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 2.5308 - accuracy: 0.3887\n",
            "Epoch 57/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 2.5026 - accuracy: 0.3947\n",
            "Epoch 58/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 2.4696 - accuracy: 0.4028\n",
            "Epoch 59/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 2.4376 - accuracy: 0.4056\n",
            "Epoch 60/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 2.4047 - accuracy: 0.4108\n",
            "Epoch 61/100\n",
            "60750/60750 [==============================] - 21s 347us/sample - loss: 2.3857 - accuracy: 0.4151\n",
            "Epoch 62/100\n",
            "60750/60750 [==============================] - 21s 353us/sample - loss: 2.3582 - accuracy: 0.4217\n",
            "Epoch 63/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 2.3343 - accuracy: 0.4246\n",
            "Epoch 64/100\n",
            "60750/60750 [==============================] - 21s 347us/sample - loss: 2.3044 - accuracy: 0.4328\n",
            "Epoch 65/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 2.2844 - accuracy: 0.4353\n",
            "Epoch 66/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 2.2889 - accuracy: 0.4369\n",
            "Epoch 67/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 2.2405 - accuracy: 0.4445\n",
            "Epoch 68/100\n",
            "60750/60750 [==============================] - 21s 347us/sample - loss: 2.2214 - accuracy: 0.4491\n",
            "Epoch 69/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 2.2479 - accuracy: 0.4436\n",
            "Epoch 70/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 2.2843 - accuracy: 0.4400\n",
            "Epoch 71/100\n",
            "60750/60750 [==============================] - 21s 347us/sample - loss: 2.2456 - accuracy: 0.4468\n",
            "Epoch 72/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 2.1923 - accuracy: 0.4566\n",
            "Epoch 73/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 2.1703 - accuracy: 0.4570\n",
            "Epoch 74/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 2.1360 - accuracy: 0.4687\n",
            "Epoch 75/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 2.1041 - accuracy: 0.4724\n",
            "Epoch 76/100\n",
            "60750/60750 [==============================] - 21s 351us/sample - loss: 2.0836 - accuracy: 0.4771\n",
            "Epoch 77/100\n",
            "60750/60750 [==============================] - 21s 352us/sample - loss: 2.0609 - accuracy: 0.4805\n",
            "Epoch 78/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 2.0397 - accuracy: 0.4856\n",
            "Epoch 79/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 2.0273 - accuracy: 0.4881\n",
            "Epoch 80/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 2.0050 - accuracy: 0.4960\n",
            "Epoch 81/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 1.9918 - accuracy: 0.4959\n",
            "Epoch 82/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 1.9617 - accuracy: 0.5023\n",
            "Epoch 83/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 1.9537 - accuracy: 0.5048\n",
            "Epoch 84/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 1.9353 - accuracy: 0.5106\n",
            "Epoch 85/100\n",
            "60750/60750 [==============================] - 21s 347us/sample - loss: 1.9188 - accuracy: 0.5105\n",
            "Epoch 86/100\n",
            "60750/60750 [==============================] - 21s 347us/sample - loss: 1.9043 - accuracy: 0.5141\n",
            "Epoch 87/100\n",
            "60750/60750 [==============================] - 21s 347us/sample - loss: 1.8844 - accuracy: 0.5186\n",
            "Epoch 88/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 1.8716 - accuracy: 0.5232\n",
            "Epoch 89/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 1.8565 - accuracy: 0.5244\n",
            "Epoch 90/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 1.8410 - accuracy: 0.5258\n",
            "Epoch 91/100\n",
            "60750/60750 [==============================] - 21s 350us/sample - loss: 1.8253 - accuracy: 0.5320\n",
            "Epoch 92/100\n",
            "60750/60750 [==============================] - 21s 352us/sample - loss: 1.8140 - accuracy: 0.5334\n",
            "Epoch 93/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 1.7976 - accuracy: 0.5375\n",
            "Epoch 94/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 1.7847 - accuracy: 0.5394\n",
            "Epoch 95/100\n",
            "60750/60750 [==============================] - 21s 349us/sample - loss: 1.7686 - accuracy: 0.5424\n",
            "Epoch 96/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 1.7519 - accuracy: 0.5462\n",
            "Epoch 97/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 1.7437 - accuracy: 0.5494\n",
            "Epoch 98/100\n",
            "60750/60750 [==============================] - 21s 347us/sample - loss: 1.7337 - accuracy: 0.5498\n",
            "Epoch 99/100\n",
            "60750/60750 [==============================] - 21s 348us/sample - loss: 1.7147 - accuracy: 0.5575\n",
            "Epoch 100/100\n",
            "60750/60750 [==============================] - 21s 346us/sample - loss: 1.7025 - accuracy: 0.5573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14sD1nUgp7uf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_text = lines[20]\n",
        "def generate_text_seq(model, tokenizer, text_seq_length, seed_text, n_words):\n",
        "    text = []\n",
        "    for _ in range(n_words):\n",
        "        encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=text_seq_length, truncating='pre')\n",
        "        y_pred = model.predict_classes(encoded)\n",
        "        predicted_word = ''\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == y_pred:\n",
        "                predicted_word = word\n",
        "                break\n",
        "        seed_text = seed_text + ' ' + predicted_word\n",
        "        text.append(predicted_word)\n",
        "    return ' '.join(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xDPx0OFw1p5",
        "colab_type": "code",
        "outputId": "cf67d169-5af3-4588-ae95-dda8c6c7772f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#seed_text = \"Once there was an old man who had four sons <eos> All four of them were very lazy <eos> One day the old man fell sick and was counting his last days in bed <eos> He worried a lot about his sons future as the young men hesitated a lot\"\n",
        "#seed_text = seed_text.lower()\n",
        "print(seed_text)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "had fallen in long ago and an enormous sycamore had grown on the spot where the sacristy had once stood he decided to spend the night there he saw to it that all the sheep entered through the ruined gate and then laid some planks across it to prevent the flock\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVAssJprw3v4",
        "colab_type": "code",
        "outputId": "50186f32-6c7e-4b26-c9bf-d192bdd14296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "generate_text_seq(model, tokenizer, seq_length, seed_text, 100)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from wandering to the window the camel driver understood nature had been a party but had caused him to do you am in the middle of the desert and the woman told him about several hours meanwhile i have to worry she went to the old king and all the sheep he had discovered before the presence of the caravan and converse with him and purpose and felt as they reached to him but the boy had to be the same stars and the boy spoke to the boy and they were in from rock places he thought to the'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sduBje0QxGlm",
        "colab_type": "code",
        "outputId": "d2496454-ffa3-4da1-d570-4d1b4eafd815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "lines[70]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'flock from wandering away during the night there were no wolves in the region but once an animal had strayed during the night and the boy had had to spend the entire next day searching for it he swept the floor with his jacket and lay down using the book he'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lpv4u_8ml6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_text = \"he boy had dreamed of the treasure he had no idea where the treasure is but he was sure it was somewhere hidden in the mountains\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVYRctIqr4Pn",
        "colab_type": "code",
        "outputId": "f93b3b29-cd18-4e63-e41a-e658fc4bbfbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "generate_text_seq(model, tokenizer, seq_length, seed_text, 100)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'just to see the language of the world and the boy couldnt understand what he was going to have to pay anything to mecca the boy said but i could have to learn it to you that your flock across the fields it always like to change the future i should be a pleasant surprise he told the bar one night the boy looked at the east to chant a small place and all the boy and presented him food and onto the boy was shocked the old man knew how to read the boys thoughts just as he himself'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5T3afbpr5Sj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('modeltrained3.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfi5HBKdv7EN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "# saving\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfSVtYAAG7Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}